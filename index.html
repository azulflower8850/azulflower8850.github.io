<!DOCTYPE html>

<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<!--<meta name="viewport" content="width=device-width, initial-scale=1">-->
	<meta name="viewport" content ="width=device-width,initial-scale=1,user-scalable=yes" >
	<!--Bootstrap -->
	<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">
	<link href="css/scrolling-nav.css" rel="stylesheet">
	<link rel="stylesheet" type="text/css" href="font-awesome-4.5.0/css/font-awesome.css">
	<link rel="stylesheet" href="css/w3.css">


	<meta name="description" content="">
	<meta name="Kevin Zhang" content=>

	<title>Kevin Zhang</title>

	<!-- Custom Fonts -->
	<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
	<link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
	<!-- Favicons -->
	<link rel="shortcut icon" href="favicon3.ico" type="image/x-icon">
	<link rel="icon" href="favicon3.ico" type="image/x-icon">
	<!-- Custom CSS -->
	<link rel='stylesheet' type='text/css' href='style.css'>


</head>

<body id="page-top">

	<nav class="navbar navbar-default navbar-fixed-top navbar-shrink" role="navigation">
		<div class="container">
			<div class="navbar-header page-scroll">
				<button type"button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand page-scroll" href="#page-top">Kevin Zhang</a>
			</div>

			<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
				<ul class="nav navbar-nav navbar-right">
					<li class="hidden">
						<a class="page-scroll" href="#page-top"></a>
					</li>
					<li >
						<a target="_blank" href="https://drive.google.com/file/d/0B6-SxZvJ7FNNck4zcWltdWZvdlE/view?usp=sharing">Resume</a>
					</li>
					<li>
						<a class="page-scroll"  href="about.html">About Me</a>
					</li>
					<li>
						<a class="page-scroll"  href="portfolio.html">Portfolio</a>
					</li>
					<li>
						<a class="page-scroll" href="#socialsection">Social</a>
					</li>
					<li>
						<a  href="mailto:kevin.zhang@students.olin.edu">Contact Me</a>
					</li>
				</ul>
			</div>
		</div>

	</nav>


	<div class="banner">
		<div class="container">
			<h1> KEVIN ZHANG </h1>
			<i class="fa fa-minus fa-2x" aria-hidden="true"></i>
			<h3> I like helping make things smarter, whether it be technology, design, or people. </h3>
			<a href="#intro" class=" page-scroll btn btn-primary btn-lg"><i class="fa fa-arrow-down"></i> Learn More </a>
		</div>
	</div>




	<div class"centeringstuff">
		<div id="intro">
			<div class="container">
				<div class="intro-section">
					<h1>Hi, I'm Kevin Zhang.</h1>
					<img src="Images/ME.jpg" class="img-circle img-centered" style="width:300px;height:400px">
					<br>
					<br>
					<h2>I do many things, but mainly I am a:</h2>
							 <div class="mySlides w3-animate-left">
										<h2> Computational Roboticist </h2>
								 </div>
							 <div class="mySlides w3-animate-left">
	 									 <h2> Software Developer </h2>
	 							</div>
							 <div class="mySlides w3-animate-left">
										<h2> UX Designer </h2>
							 </div>
							 <div class="mySlides w3-animate-left">
										<h2> Student </h2>
							 </div>
				</div>
			</div>
		</div>

	<!-- About Section -->
		<section id="about" class="about-section">
			<div class="container">


				<h2>About Me</h2>

				<p>I am a junior at Franklin W. Olin College of Engineering, majoring in Computational Robotics Engineering with a concentration in Computer Science. It's a self-made major that combines the technology and expanding topics in robotics with the knowledge and implementation skills of computer science. I am deeply passionate about both software and robots, and as a most curious cat, I just couldn't say no to either one! An avid proponent of the balanced work/life philosophy, I strive for a challenge and endeavor nonstop to learn and contribute, but also pause sometimes to enjoy the small things in life.</p>

				<br>
				<br>

				<blockquote>
					<p>
						"Kevin ... worked on a system for helping with internal testing, interfacing with various sets of hardware and writing algorithms based on data received from said hardware. He jumped right into the challenge, learning the project background quickly, and contributed significantly to the success of the project ... The work resulted in a technology concept which will add to the patent portfolio at Ivani. Kevin’s natural intelligence and commitment to the company were evident throughout the summer. He naturally adapted to our culture, while impacting it in a positive way. Having Kevin work with us for the summer was awesome, and I would not hesitate in recommending him to future employers."
					</p>
					<cite>
						 - Matthew Wootton, Chief Technology Officer at Ivani LLC
					</cite>
				</blockquote>

				<br>
				<br>


				<p>In academics, I study hard in class and lead the Olin Edwin Robotics and Olin Aquaponics teams. I actively do a lot of self-learning in the fields of artificial intelligence and mobile robotics, with new C++ programming chops mixed in as well. I also play ultimate frisbee, piano, and tennis to keep fit and maintain my skills. Outside of school, I have fun pursuing varying ventures such as building an electric go kart to ride to the dining hall or cooking new recipes in the kitchen. I enjoy learning new things, hanging out with friends, and eating food. A relentless pursuer of all three prongs of the urban legend's academic triangle of Sleep, Friends, and Knowledge, people back at home knew me as a man famous for his (ocassional) loudness and bright laughter, and the one you can always depend on.</p>


				<br>
				<br>


			</div>
				<div class="centeringstuff">
				<div class="container">
					<h3> Want learn more about me? Click below. </h3>
					<a href="about.html" class=" page-scroll btn btn-primary btn-lg"><i class="fa fa-arrow-right"></i> More About Me </a>
				</div>
			</div>

		</section>





	<!-- Portfolio Section -->






		<section id="portfolio" class="portfolio">
			<div class="container">
					<div class="intro-section-2">

						<h2>My Experience</h2>
					</div>

					<div class="row">

						<div class="col-md-4 portfolio-item">
							<a href="#nutonomy" class="portfolio-link" data-toggle="modal">
								<div class="portfolio-hover">
									<div class="portfolio-hover-content">
										<i class="fa fa-plus fa-3x"></i>
									</div>
								</div>
								<img src="Images/nutonomy_logo.jpg" class="img-responsive rounded-corners"style="width:400px;height:300px;">
							</a>
							<div class="portfolio-caption">
								<h4>nuTonomy</h4>
								<p class="text-muted">Summer 2017 Internship</p>
							</div>
						</div>

						<div class="col-md-4 portfolio-item">
							<a href="#ivani" class="portfolio-link" data-toggle="modal">
								<div class="portfolio-hover">
									<div class="portfolio-hover-content">
										<i class="fa fa-plus fa-3x"></i>
									</div>
								</div>
								<img src="Images/IvaniLogo.jpg" class="img-responsive rounded-corners"style="width:400px;height:300px;">
							</a>
							<div class="portfolio-caption">
								<h4>Ivani</h4>
								<p class="text-muted">Summer 2016 Internship</p>
							</div>
						</div>

						<div class="col-md-4 portfolio-item">
							<a href="#edwin" class="portfolio-link" data-toggle="modal">
								<div class="portfolio-hover">
									<div class="portfolio-hover-content">
										<i class="fa fa-plus fa-3x"></i>
									</div>
								</div>
								<img src="Images/Edwin.jpg" class="img-responsive rounded-corners" style="width:400px;height:300px;">
							</a>
							<div class="portfolio-caption">
								<h4>Edwin</h4>
								<p class="text-muted">Olin Robotics Lab</p>
							</div>
						</div>
					</div>


				<!-- Proxy Spacer -->


				<div class="proxy" >
					<img src="Proxy.jpg" style="width:400px;height:50px;">
				</div>


				<div class="intro-section-2">
						<h2>Portfolio Highlights</h2>
				</div>

				<div class="row">

					<div class="col-md-4 portfolio-item">
						<a href="#nevo" class="portfolio-link" data-toggle="modal">
							<div class="portfolio-hover">
								<div class="portfolio-hover-content">
									<i class="fa fa-plus fa-3x"></i>
								</div>
							</div>
							<img src="Images/project_nevo.jpg" class="img-responsive rounded-corners" style="width:400px;height:300px;">
						</a>
						<div class="portfolio-caption">
							<h4>Project: Nevo</h4>
							<p class="text-muted">Computational Mobile Robotics</p>
						</div>
					</div>

					<div class="col-md-4 portfolio-item">
						<a href="#frost" class="portfolio-link" data-toggle="modal">
							<div class="portfolio-hover">
								<div class="portfolio-hover-content">
									<i class="fa fa-plus fa-3x"></i>
								</div>
							</div>
							<img src="Images/Frost.jpg" class="img-responsive rounded-corners" style="width:400px;height:300px;">
						</a>
						<div class="portfolio-caption">
							<h4>Frost</h4>
							<p class="text-muted">Stark Industries</p>
						</div>
					</div>

					<div class="col-md-4 portfolio-item">
						<a href="#aquaponics" class="portfolio-link" data-toggle="modal">
							<div class="portfolio-hover">
								<div class="portfolio-hover-content">
									<i class="fa fa-plus fa-3x"></i>
								</div>
							</div>
							<img src="Images/AquaponicsLogo.jpg" class="img-responsive rounded-corners"style="width:400px;height:300px;">

						</a>
						<div class="portfolio-caption">
							<h4>Aquaponics</h4>
							<p class="text-muted">OWL Extension Project Team</p>
						</div>
					</div>


				</div>
				<div class="centeringstuff">
					<div class="container">
						<h3> Want to see more of my portfolio? Click below. </h3>
						<a href="portfolio.html" class=" page-scroll btn btn-primary btn-lg"><i class="fa fa-arrow-right"></i> Full Portfolio </a>
					</div>
				</div>

			</section>







	<div class="portfolio-modal modal fade" id="nutonomy" role="dialog" aria-hidden="true">
		<div class="modal-content">
			<div class='close-modal' data-dismiss="modal">
				<div class="lr">
					<div class="rl">
					</div>
				</div>
			</div>

			<div class="container">
				<div class="row">
					<div class='col-md-8 col-md-offset-2'>
						<div class="modal-body">
							<h2>nuTonomy</h2>
							<p class="item-intro text-muted">Autonomous Vehicle Intern</p>

							<p class="item-intro text-muted">Summer 2017</p>

							<div class="row">
								<div class="col-md-12">
									<img class="img-responsive" src="Images/nutonomy_team.jpg" style="width:100%; height:400px">
								</div>
							</div>

							<div class="row">
								<div class="col-md-4">

									<img class="img-responsive" src="Images/nuZebra_overview.png" style="width:100%; height:170px">

								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/nuZebra_home.png" style="width:100%; height:170px">

								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/nuZebra_page.png" style="width:100%; height:170px">

								</div>
							</div>

							<div class="row">
								<p> (Above) A team picture of the crew. (Bottom three) snapshots of an MVP of nuZebra.</p>
							</div>

							<br>
							<br>

							<p class="content-body">nuTonomy is a fast-paced startup with a bold mission of completely changing the urban transportation scene. They aim to create their own fully functioning system that enables perception, localization, mapping, planning, controls, and safety for an autonomous vehicle. And their software, nuCore, is on track to make it a reality. As one of the only two undergraduate interns given the opportunity to work with nuTonomy over the summer, I dived right into the fray to not only learn more about the world of driverless cars but also contribute to the company and help them reach their goal.</p>

							<p class="content-body"> At the start of the internship, I was tasked with the formal project of creating a smart diagnostics tool for Team Car, the group that interfaced most closely with the autonomous cars themselves. I was to work alone on the project, and the only major requirements were that it could scan as many aspects of the car as possible and provide immediate feedback as to the car's condition, and that it remain easily usable, maintainable, and modifiable, as future users might find a new problem that they would want added. Doing my own research, I realized that Team Car was largely responsible for software road release testing, car maintenance and conversions, as well as code debugging and software release management. Whenever a problem was discovered, such as a car breaking down or the code not working, Team Car would have to go down a large list of possible problems and manually check them one by one. Observing them one time attempting to figure out why a car wouldn't start, I found that it could take them up to a week just to resolve an issue before even starting with testing or more productive items, and often times the same type problem would occur, making it seem like the team was running in circles. The goal for my tool was to automate this process, and prevent unnecessary manual labor from hindering progress on the software new releases. Thus I began to work on the tool, later naming it nuZebra (zebra is slang for "exotic diagnosis" in medical circles). </p>

							<p class="content-body"> To begin, the tool needed to be scalable, yet fast and accurate. Since a number of people in the company weren't software majors, the tool also needed to be easily usable by a lay man. I used Python and PyQt as my main interfaces because the company was most familiar with these libraries across the various teams. I decided to build the tool from the ground up and use an iterative process to prototype increasingly complex interfaces and frameworks, taking into account feedback from others. I spent most of my first six weeks creating the backend framework, making sure to establish a modular, multi-layered code architecture, such that later code modifications were easy and did not disrupt the core of the software. After finishing the backend mechanism and ensuring proper functionality of the tool, I turned to content creation and front end design. Since the software I was creating was meant to be an internal tool used by the company itself, I decided to hold weekly meetings with company members to get their input on how the tool looked and felt. Near the end of the summer I also held a Team Car-wide meeting to get their feedback on the UI, since they were most likely to be the main users. I ended up designing a highly minimalistic interface with nuTonomy's color scheme and simplistic buttons as the main interactive mechanism. All data and information was split into high level and lower level types, with high level immediately displayed and lower level accessible with the push of a button. The tool covered software statuses and release versions, sensor statuses and incoming data, as well as system information and hardware data. There was also room for car CAN bus data as well as mechanical outputs, but due to time constraints I could only create the framework for those. After many iterations and much polishing, I was able to deliver a fully functional, well designed nuZebra to Team Car. </p>

							<p class="content-body"> In addition to its completion, I was also able to deploy my tool onto the cars. We tested nuZebra on the autonomous cars to great success, and even went out on a software road release after using it to efficiently ascertain the status of the car. The team was glad that they could now spend less nights working at the company, and my manager was even surprised by the ease of use and amount of data I was able to incorporate into nuZebra. They plan to use it for future testing and incorporate it into their formal car startup and road release sequences. </p>

							<div class="row">
								<div class="col-md-4">

									<img class="img-responsive" src="Images/RL_Start.gif" style="width:100%; height:300px">

								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/RL_Training_Final.gif" style="width:100%; height:300px">

								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/RL_Final_Final.gif" style="width:100%; height:300px">

								</div>
							</div>

							<div class="row">
								<p> (Left to Right) Visualizations showing the proof of concept of the Reinforcement Learning environment being implemented on a parked car avoidance scenario, first starting out, then training 1500 trials, and then converged behavior after 1500 trials.</p>
							</div>

							<p class="content-body"> My main project was going so well, that at some point I realized I was almost a month ahead of schedule. With my manager's approval, I decided to seek out new side projects where I could help other teams on as well, since I had the extra time and desire to learn about what other teams were doing.</p>

							<p class="content-body"> I found a side project with the perception team, who was looking for a way to automate config/param loading and execution. At the time, for every different scenario or car, the team had to write up a brand new config file, and then manually load it into the system upon runtime. This resulted not only in slow testing iteration, but also created a troublesome 100+ file structure in the codebase due to massive numbers of config files that had to be saved, most of them being identical save a few differences for different maps or scenarios. I then helped the perception team design a config generator that could automatically create config files in real time. It utilized a pool of possible config templates, and then with a few parameters could build a new config file for that specific run of the system. The generator was also wrapped up as a nice executable module, so all one had to do was call it and it would run with the given parameters. The generator was also built to be highly modular, so the parameter/config file could be customized as much or as little as one wanted. The config generator ended up cleaning up a huge section of the codebase, and since it could be called at runtime, streamlined execution of the nuCore system. </p>

							<p class="content-body"> Due to the first one going so smoothly, I also found a second side project to work on. The planning team head was curious about potentially incorporating new models into the planner that determined how the autonomous car moves, and he wanted someone to spend time exploring different types of planning models. The planning team head noted he believed that there is a fair chance the optimal planner would require both deterministic and nondeterministic models to fully account for all possibilities. Since the current model is mostly deterministic and operates using on a priority-rule based system, he wanted me to research nondeterministic models and their feasibility in solving complex problems. After much digging, I learned about multiple different options, such as Sequential Game Theory, Value Iteration, and Learned based models. I became very interested in Reinforcement Learning as a potential candidate. Since it was the backbone of AI achievements such as conquering Go, Chess, and most recently a multiplayer online video game known as Dota 2, I thought it might work as a suitable model. I did a lot of offline self-learning and research in an effort to fully understand Reinforcement Learning and how it might work in mobile robotics planning. Towards the end of my internship, I was able to construct a Reinforcement Learning environment that solved mobile robotics problems. I then applied it to a parked car scenario and created an MVP, which I presented to the planning team lead. Due to time constraints, I used a fairly simplistic Reinforcement Learning implementation, where I built a discretized space and mapped it to a Q-Learning algorithm. The position of the vehicle was considered the state space, and the actions in this instance were discretized to be turn left, turn right, go straight, or stop. I then used an advanced form of the Bellman equation with a simulator that I built to simulate a converged behavior of the autonomous vehicle successfully navigating its way through the scenario. The MVP showed that RL-based models could be feasible for autonomous car planning, albeit some caveats and further research needed to more concretely ascertain its exact usefulness. The planning team was grateful for my efforts in exploring an unknown territory for them, and said they plan on looking into it with more scrutiny in the future. </p>

							<p class="content-body"> My experience with nuTonomy was an amazing and symbiotic one. An autonomous vehicle company like nuTonomy was my dream company for this summer, and I got my wish granted. I worked harder than I ever had before for a company, and helped them optimize their codebase, improve their testing and car system, as well as introduce new potential models to the planning team. In turn, they gave me so much advice and taught me many things about mobile robotics, planning, and AI systems. Most importantly, they helped me finalize my decision to pursue mobile robotics as my career path. Moving forward, I hope to immerse myself further into the world of robotics and intern at a larger robotics company to gain even more experience. I look forward to the day I can see a nuTonomy taxi on the roads in Boston. </p>


							<ul>
								<li>
									<a target="_blank" href="http://www.nutonomy.com">
										<i class="fa fa-globe fa-3x"></i>
									</a>
								</li>
							</ul>

							<button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Close Internship </button>





						</div>
					</div>
				</div>

			</div>
		</div>
	</div>



		<div class="portfolio-modal modal fade" id="ivani" role="dialog" aria-hidden="true">
			<div class="modal-content">
				<div class='close-modal' data-dismiss="modal">
					<div class="lr">
						<div class="rl">
						</div>
					</div>
				</div>

				<div class="container">
					<div class="row">
						<div class='col-md-8 col-md-offset-2'>
							<div class="modal-body">
								<h2>Ivani</h2>
								<p class="item-intro text-muted">Software Engineering Intern</p>

								<p class="item-intro text-muted">Summer 2016</p>

								<p class="text-muted">Note: I am currently under a special IP contract, but I'll do my best to convey my work.</p>


								<div class="row">
									<div class="col-md-6">

										<img class="img-responsive" src="Images/IvaniVisual.jpg" style="width:100%; height:400px">

									</div>
									<div class="col-md-6">

										<img class="img-responsive" src="Images/IvaniVisual2.jpg" style="width:100%; height:400px">

									</div>
								</div>

								<div class="row">
									<p> A basic visual of the technology my team created </p>
								</div>

								<br>
								<br>

								<div class="row">
									<div class="col-md-8 col-md-offset-2">
										<iframe width="100%" height="315px" src="https://www.youtube.com/embed/DMNm2MQnWek" frameborder="0" allowfullscreen></iframe>
									</div>
								</div>

								<p class="content-body">Ivani is a start up working on revolutionary network presence sensing technology that allows wireless communication systems to observe RF disturbances without the addition of new hardware. It then analyzes these disturbances to determine the physical occupancy of a person inside a room. As a college freshman, Ivani took a chance on me as a student with comparatively less experience but equipped with a wide array of skills and a bright motivation to learn and make an impact, and I seized the opportunity to deliver. </p>

								<p class="content-body">Teamed up with fellow Oliner Liani Lye, I was assigned the task of creating a testing module for the company's original presence sensing system, with the idea being to train the original. We exceeded the project goals and ended up developing a brand new patent-pending presence sensing technology that not only trained the original system but could also act as a stand alone presence detection system. The technology we created both detects a person's physical presence, and also determines where the person is in reference to the detection field, such as how far away they are, whether they are approaching the room or moving away, etc. What's special about the technology is that it doesn't require any new hardware; all nodes of the system can come from off-the-shelf hardware that most households already possess. This makes our technology both extremely modular and easily integrated into existing systems. Our team was well organized with weekly sprints and check-ins with each other and our supervisor, constant communication and pair programming, as well as occasional personal conversation to ensure best performance from the team. Because we were trying to create something that had never been done before, we used a very systematic approach, first performing many tests and experiments to understand more about the system, then breaking down the problem into smaller portions that we would individually tackle, and then eventually re-combining the pieces using an iterative process. My role on the team for this project mainly involved designing the software algorithms and optimizing them, as well as writing firmware for sensor hardware. I was also involved in sensor fusion and decision making, trying to understand the data we were seeing as well as mapping out where the user is in context to the detection system. We ended with an MVP that interfaced with a Raspberry Pi and created a network of sensors on the user, in rooms, and in the hallways. It determined presence, relative location of the user to a room, and real time movements of the user. Our creation will streamline further development of the full-timers' main presence sensing technology and expand the company's repertoire of presence sensing capabilities. Our work paved the way for Ivani's next projects in the pipeline, People Counting and People Locating.</p>

								<p class="content-body"> In addition to the main project, Liani and I also thought up a secondary project that we believed could augment the main project we were working on. I personally spearheaded this exploratory venture, and I ended up creating a sensor construct that integrated additional data streams to improve the output of the main project. The process for this project mirrored that of the main. The augmentation I created stabilized the main algorithm and provided more consistent and accurate outputs. Because of the additional sensors I integrated into the system, we also created the framework for the ability of the technology to learn trends and statistics, thus being able to predict the pathway that a user will most likely take in a home and optimize lighting or other appliances. The construct I added to the original project ended up increasing accuracy of outputs and predictions by about 40%, thus significantly boosting the system's performance.  </p>

								<p class="content-body"> The technology we were creating was so new that we eventually realized that it could be patented. We contributed to a patent application on this new technology, effectively bolstering company assets. The patent, <i>Reverse-Beacon Indoor Positioning System Using Existing Detection Fields</i>, is currently submitted and is in progress for filing. The company estimates that the patent will be worth at least $300,000 once it's completely filed and being utilized.</p>

								<p class="content-body"> Besides the main projects I worked on, I also took initiative to take on several smaller quality of life projects not just for my team but also for the company as a whole. I flushed out a modular code architecture for future software development that increased code readability and organization and also provided easier development of new codebases. The framework compartmentalized the presence sensing process into three main parts, and outlined general methods that all processes should use. The architecture was actually implemented in our team codebase and made both communication and debugging much more efficient. I also laid the foundations for test-driven development by conceptualizing a unit testing system that allowed for more optimized development. I not only designed a robust unit testing process but also wrote a comprehensive guide to allow the full timers to learn about the system on their own time. While the system isn't currently being used because the company is still small enough such that direct communication is faster, the company definitely believes that it will come into use once the company grows further and a more organized system will be needed. Finally, I helped characterize test inputs for system development, running various experiments to help the company better understand the data they were reading. I actually came to several conclusions that gave the full-timers many new things to consider moving forward, such as trends in the data and previously unknown traits that occasionally will be exhibited under certain conditions. Using data analytics, I ended up finding a flaw in the current microcontroller the company was using and confirmed the need to switch to a new microcontroller, which was two times faster and much more consistent. </p>

								<p class="content-body"> Overall, the Summer of 2016 has been the most fun, most educational, and most accomplished summer I've ever had. I believe that both Ivani and I have benefitted greatly from this experience, and I can't wait to see what's next, for me and Ivani. </p>

								<ul>
									<li>
										<a target="_blank" href="http://www.ivani.com/network-presence-sensing.html">
											<i class="fa fa-globe fa-3x"></i>
										</a>
									</li>
								</ul>

								<button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Close Internship </button>





							</div>
						</div>
					</div>

				</div>
			</div>
		</div>




			<!--Portfolio Modal 2-->

			<div class="portfolio-modal modal fade" id="edwin" role="dialog" aria-hidden="true">
				<div class="modal-content">
					<div class='close-modal' data-dismiss="modal">
						<div class="lr">
							<div class="rl">
							</div>
						</div>
					</div>

					<div class="container">
						<div class="row">
							<div class='col-md-8 col-md-offset-2'>
								<div class="modal-body">
									<h2>Collaboratory EUsocial Coworker Edwin</h2>
									<p class="item-intro text-muted">Research Project Lead - Olin Robotics Lab</p>

									<p class="item-intro text-muted">Fall 2015 - Present</p>


									<div class="row">
										<p> Fall 2015</p>
									</div>

									<div class="row">
										<div class="col-md-6 col-md-offset-3">
											<iframe width="100%" height="300px" src="https://www.youtube.com/embed/IV-uooCVgGs" frameborder="0" allowfullscreen></iframe>
										</div>
									</div>

									<p class="content-body">In the Fall of 2015, my first semester at Olin College, I joined the school's Robotics Lab, eager to learn more about robots and how they worked. I decided to work with the lab's head programmer, Sophia Li, on Edwin, a robotic arm. Our objective was to program Edwin to respond to certain stimuli and interact with users with poses and gestures. Coding was done in Python, and ROS was used as the bridge between Python and Edwin. I mainly focused on creating motion algorithms that Edwin would use to respond to certain signals from the user. At the Olin Expo, we presented our semester's work, which culminated in Edwin playing Tic-Tac-Toe against himself. Our presentation went really well, and many were fascinated in our robot's ability to draw the grid and shapes so accurately.</p>

									<div class="row">
										<p> Spring 2016</p>
									</div>
									<div class="row">
										<div class="col-md-6">
											<iframe width="100%" height="300px" src="https://www.youtube.com/embed/yZWK3U_afgc" frameborder="0" allowfullscreen></iframe>
										</div>
										<div class="col-md-6">
											<iframe width="100%" height="300px" src="https://www.youtube.com/embed/jjyEv3PJ6AQ" frameborder="0" allowfullscreen></iframe>
										</div>
									</div>

									<p class="content-body">In the Spring of 2016, we took things a step further, working to synthesize a comprehensive and realistic interaction sequence, where people can talk to and play with Edwin as if he were a real live “dinosaur”. This time I took on a larger role, working closely with Sophia to plan out and create interactions and behaviors. I was involved in a lot more projects this time. First I decided that a moving jaw was better than a slack jaw, so I scrounged up a servo and managed to write a modular program in C++ for an Arbotix board that would allow us to control Edwin's lower jaw. I also spent quite a bit of time figuring out touch sensitivity. One thing we thought would be really cool was if Edwin could react to touch. I worked on programming an accelerometer in C++ not only how to recognize when it's being touched but also to differentiate between a pat and a slap. After all this hardware work, I partnered up with Sophie to connect all the pieces together by creating a "brain" module where all information was fed to and where all actions were executed in response to stimuli. Finally after we had finalized the interaction sequences, my last job of the semester was to generate all the motion behavior algorithms that would be used in the interactions. Overall, I wrote almost 50 different behaviors for Edwin. Once again, we presented our work at EXPO, and Edwin dominated by beating people left and right at Tic-Tac-Toe. But challengers continued to arrive, and our table was crowded as people were amazed by Edwin's almost "human-like" behaviors. </p>

									<div class="row">
										<p> Fall 2016</p>
									</div>
									<div class="row">
										<div class="col-md-6">
											<iframe width="100%" height="300px" src="https://www.youtube.com/embed/QB8nBHxtrKg" frameborder="0" allowfullscreen></iframe>
										</div>
										<div class="col-md-6">
											<iframe width="100%" height="315px" src="https://www.youtube.com/embed/xjIaE0qrZJk" frameborder="0" allowfullscreen></iframe>
										</div>
									</div>

									<p class="content-body">In the Fall of 2016, I decided to borrow some concepts from my internship at Ivani during the past summer. My goal was to accomplish presence detection, or give Edwin the ability to detect the physical body of users inside a room and follow them around or create playful interactions, such as responding to hand waves. I worked a lot in C++ and Python this semester, and I delved heavily into APIs, computer vision, algorithms, and machine learning. To start, I did a lot of research into Cmakelists and experimenting with the sample code to get the Kinect Nite API working on Edwin's system by figuring out how to interface C++ with ROS. I then wrote Python scripts to communicate to my C++ scripts via rostopics and wrote various data structures and algorithms to keep track of and remember detected bodies. Combined with motions from Edwin's behavior repertoire, I was able to make Edwin physically respond when a person enters his field of vision, creating presence detection. I further developed the code to keep track of coordinates, and using tf transforms in ROS with rotating reference frames, I was able to make Edwin move to specified coordinates in response to the location of the person of interest. This then gave Edwin the ability to follow users around a room. I was also able to have Edwin detect and keep track of a person's hand. I developed this module so Edwin can detect when a person waves his hand by searching for a repetitive sweeping motion. Finally, I integrated these two pieces into one interaction sequence, where an approaching user will prompt Edwin to greet them and begin following them, and when that user waves, Edwin will respond happily. The interaction sequence can then be toggled on and off to lead into other interactions sequences or follow people while idle. Overall, I made Edwin feel a lot more autonomous and intelligent by giving him the ability to find people on his own and follow them. When we presented Edwin at EXPO, people were wow'ed by Edwin's ability to recognize hand waves, and many were very impressed by Edwin's interactivity, as my presence detection module made him feel personal and alive. </p>

									<div class="row">
										<p> Spring 2017</p>
									</div>
									<div class="row">
										<div class="col-md-6 col-md-offset-3">
											<iframe width="100%" height="315px" src="https://www.youtube.com/embed/jjtzRMgB_cY" frameborder="0" allowfullscreen></iframe>
										</div>
									</div>

									<p class="content-body"> In the Spring of 2017, I became the full-time Project Lead of Team Edwin. It was a substantial shift, but I was up to the challenge. This time I worked on a project with my former Project Lead, Sophie Li, as well as two freshmen, Yichen and Katya. We were creating Project: Simon Says, where Edwin could play Simon Says with other users, and could play both as Simon and as a Player. We wanted the game to be as close to a game between two humans as possible, so the only fully digitalized portions were the cognitive ones such as deciding if a player had followed intructions properly or figuring out whether or not to move based what Simon said. I would work mainly on having Edwin learn new movements for when he was a player so he could decide whether or not to move and then how to move based on instructions from the user Simon. I also headed the project and thus was in charge of integrating the other members' work on other parts of the game, such as talking and listening, recognizing a user Player's movements, and so on. I utilized Python and C++ once again and immersed myself in computer vision, speech recognition, and machine learning. I created a massive pool of basic movements, and then created a speech recognition library to catch for keywords that would hint at a particular command. Once the command was decided based on what the user stated, Edwin would construct a complex movement sequence from his pool of basic movements to move based on what the user Simon told him to do. There was also the added functionality of deciding whether or not to move in the first place based on whether "Simon Says" was stated. After finishing the Edwin Player module, I worked to coordinate with the other members for the Edwin Simon and speech modules. I then integrated all of our work into a comprehensive game sequence that played Simon Says from start to finish. After finishing Simon Says, I went further and helped finalize other Team Edwin's projects as well, giving aid to freshmen and pushing their project along in anticipation of the end of the year. I also helped them integrate their projects together, so that in the end there was one massive game sequence tree, where a user approached Edwin, selected from a screen of options, and then played the chosen game with Edwin. When we presented at EXPO, I was charge of the Edwin station for the first time this semester. Overall the crowd was huge as always, and everyone was impressed with the various games they could play. People were most impressed by the fluidity in which Edwin could cycle through and shift between game modes and greeting people, a result of my integration work and coordination/help from everyone on the team. Given it was my first time heading the team, things went pretty well. Going into next year, Sophie, my mentor, will have graduated, so it'll be up to me to lead the team into our next projects. I plan on improving upon what happened this year and making next year the best yet! </p>

									<ul>
										<li>
											<a target="_blank" href="https://github.com/olinrobotics/edwin">
												<i class="fa fa-github fa-3x"></i>
											</a>
										</li>
									</ul>

									<button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Close Project </button>

								</div>
							</div>
						</div>

					</div>
				</div>
			</div>






		<div class="portfolio-modal modal fade" id="nevo" role="dialog" aria-hidden="true">
			<div class="modal-content">
				<div class='close-modal' data-dismiss="modal">
					<div class="lr">
						<div class="rl">
						</div>
					</div>
				</div>

				<div class="container">
					<div class="row">
						<div class='col-md-8 col-md-offset-2'>
							<div class="modal-body">
								<h2>Project: Nevo</h2>
								<p class="item-intro text-muted">Genetic Algorithms Environment</p>

								<p class="item-intro text-muted">Spring 2017</p>


								<div class="row">
									<div class="col-md-8 col-md-offset-2">
										<iframe width="100%" height="315px" src="https://www.youtube.com/embed/8Z2Mnvjfv0Y" frameborder="0" allowfullscreen></iframe>
									</div>
								</div>



								<p class="content-body">In the Spring of 2017, for the final project of Computational Robotics, I was tasked with two other Oliners, Shane Kelly and David Zhu, to create something "cool". Given the open-ended project, we wanted to do something learning-based that was outside the "mainstream" bounds of machine learning and neural networks to explore and expand our knowledge. Shane then mentioned that genetic algorithms was a thing, and thus we began Project: Nevo.</p>

								<p class="content-body"> Genetic algorithms are as the name suggests, algorithms that take parameters/weights as "genes", and use a process similar to natural selection to evolve the genes to their optimized state. Over many iterations of choosing the "best" genes and mutating them to create potentially even stronger genes, the "most fit" gene can be found, which is then the optimized parameters for a given behavior or objective. We decided to implement a genetic algorithm environment that could teach mobile Neato robots how to perform multi-robot interactions, such as teaching a group of robots to form a line. </p>

								<p class="content-body"> David was more into codebase architecture and designing a robust code structure and software flow, so Shane and I were in charge of implementing the core of the genetic algorithm software. David created a base environment that included a modular simulator, and Shane and I worked on the Genetic Algorithm framework. We created a modular system for a generation evolution incubator that could plug and play any "task" given a fitness function and a simulation framework. We then both worked on different tasks, thus completing the environment and creating a polished product. Our approach was to establish a strong core system, and then expand from there with experimentation and iteration. Our core consisted of David's environment wrapped around our evolution system, and we expanded with new tasks while optimizing the existing codebase. Shane and I worked extensively first on making our genetic algorithm work with a simple task, and we performed many tests to find the best parameters for evolution. I then began to work on cooperative tasks, and Shane took on competitive tasks. This involved figuring out how to increase the complexity of the task while ensuring it worked with the evolution system. For cooperative tasks, I had included all Neatos' position and orientations into account and factored them all into the reward functions, with double positives doubling the reward. The simulation framework also had to factor in multiple Neatos, as they had to know each other's positions and orientations. I also took on the task of interfacing between our simulation environment and the real world, using sensor fusion and a mirrored framework to the simulation system to create a new system branch that could easily translate our optimal "genes" to the real world. I used computer vision to map our simulation into a 3D space in the real world, and then replaced simulation portions with apriltag markers and sensors. I also figured out how to apply our software onto multiple robots, thus creating a system of mobile Neatos that could interact with each other. By the end of the semester, we had implemented and optimized Neato systems for Waypoint Navigation, Linear Regression, and Tag. </p>

								<p class="content-body"> We presented our work at EXPO, and many were highly impressed with our ability to use a non-mainstream model to exhibit highly organized, intelligent behavior between multiple Neatos. Our professor was especially impressed since we showed him something he had never seen before. This project was a great learning experience and also a chance to better understand robust code structure. I learned a ton about the breadth of learning models out there from Shane, and David taught me that a codebase is never fully optimized, as there are always ways to better streamline software execution or improve code architecture. Moving forward, I want to learn more about the different methods of learning that exist, as well as work with mobile robots even more. There are so many things you can do with Neatos once you bring intelligent behavior onto the table. </p>

								<div class="row">
									<div class="col-md-4">
										<img class="img-responsive" src="Images/nevo_Single.png" style="width:100%; height:200px">
									</div>
									<div class="col-md-4">
										<img class="img-responsive" src="Images/nevo_Linear.png" style="width:100%; height:200px">
									</div>
									<div class="col-md-4">
										<img class="img-responsive" src="Images/nevo_Tag.png" style="width:100%; height:200px">
									</div>
								</div>


								<ul>
									<li>
										<a target="_blank" href="https://github.com/comprobo-final-project/comprobo_final_project">
											<i class="fa fa-github fa-3x"></i>
										</a>
									</li>
									<li>
										<a target="_blank" href="https://comprobo-final-project.github.io/">
											<i class="fa fa-globe fa-3x"></i>
										</a>
									</li>
								</ul>

								<button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Close Project </button>

							</div>
						</div>
					</div>

				</div>
			</div>
		</div>



	<div class="portfolio-modal modal fade" id="frost" role="dialog" aria-hidden="true">
		<div class="modal-content">
			<div class='close-modal' data-dismiss="modal">
				<div class="lr">
					<div class="rl">
					</div>
				</div>
			</div>

			<div class="container">
				<div class="row">
					<div class='col-md-8 col-md-offset-2'>
						<div class="modal-body">
							<h2>Frost</h2>
							<h2>Autonomous Snowball Launcher</h2>
							<p class="item-intro text-muted">Stark Industries</p>

							<p class="item-intro text-muted">Fall 2016</p>


							<div class="row">
								<div class="col-md-8 col-md-offset-2">
									<img class="img-responsive" src="Images/FrostTeam.jpg" style="width:100%; height:400px">
								</div>
							</div>


							<div class="row">
								<div class="col-md-6">
									<iframe width="100%" height="300px" src="https://www.youtube.com/embed/d-Qze-NyNgw" frameborder="0" allowfullscreen></iframe>
								</div>
								<div class="col-md-6">
									<iframe width="100%" height="300px" src="https://www.youtube.com/embed/89lQ01Aqy58" frameborder="0" allowfullscreen></iframe>
								</div>
							</div>

							<p class="content-body">In October of 2016, I teamed up with friends Cedric Kim, Daniel Daugherty, Kevin Guo, and Jeremy Garcia under the name Stark Industries to design and build an autonomous snowball launcher. With winter coming up in Boston and weather forecasts predicting a bountiful snow season this year, we wanted to collaborate and put our skill sets together to create the ultimate weapon in snowball fights. We noticed from last year's snowball fights that we were really bad at hitting the opposing team, and getting wet in the cold from snow falling into our clothes wasn't fun. We wanted to build a robot that could dominate snowball fights, with bullseye accuracy and strong defense against snow. To make some tangible goals, we set forth a number of specifications that we wanted this robot to have: it would be able to shoot up to 40 feet away, be able to automatically arm and re-arm itself within 6 seconds, find and lock on targets without any user input and fire more accurately than a human, and be able to handle the entire snowball shooting sequence from packing a snowball to firing it by itself. We named this robot Frost. </p>

							<p class="content-body">To build Frost, we decided to split up into subteams to tackle the individual components. Jeremy and I would take on software, and Cedric, Daniel, and Kevin would take on mechanical. Due to a lack of a strong electrical engineer, we decided that we would all pitch in for any electrical portions, of which there were few. We split up the project into four two-week sprints, with goals to meet each sprint. Cedric and I took informal leadership roles in our subteams as well as planning out next steps and sprint goals. Due to schedule conflicts, we decided that each member would be responsible on their own for finishing their portion of that sprint's goal, and as close friends, we trusted each other to do so. With this setup, we managed to complete the project in under 8 weeks. </p>

							<p class="content-body">In the First Sprint, we decided to first create a proof of concept that such a robot was physically possible, as there were no online sources to confirm its feasibility. Our goal was to create a prototype, a miniature catapult that could be electronically controlled. On the software team, our main goal for this sprint was to write the firmware for the Arduino that controlled the motors to actuate the catapult and turn the pan control. I worked mainly on getting the firmware logic to work with panning towards a specific direction, arming, firing a set distance, and then re-arming. Jeremy created a basic interface so that we could easily manipulate various variables to test out our catapult prototype. By the end of the sprint, we were able put together a prototype of Frost. I managed to streamline the firing sequence such that we met our goal of arming, firing, and re-arming in under 6 seconds. We tested the catapult in multiple different experiments and confirmed that it was indeed possible to create Frost. It was feasible to create an autonomous snowball launcher. We were on a roll. </p>

							<p class="content-body">For the Second Sprint, our goals became a little too ambitious. We wanted to push our limits and see how far we could get, so we decided to create all the intelligent and autonomous parts of Frost. Mechanical decided to try and build their own LIDAR and create a compactor mechanism for packing snowballs, and software decided to attempt autonomous vision tracking and interface with the LIDAR once built. For this sprint, I worked mainly on interfacing with a Kinect camera and getting computer vision to work with our prototype as well as helping out with interfacing with the LIDAR, and Jeremy worked mainly on experimenting with various methods to try to find and track a human in a camera's field of view. Jeremy found out that motion detection was a viable option, but we soon discovered that the pan motor was too often confused because the outputs weren't consistent enough. The mechanical team also did not have much luck either. At the end of the sprint, neither subteam was able to reach their goals. We decided to pivot away from a completely autonomous robot and tossed the idea of the compactor. Now the robot was autonomous starting from when a user gives it a packed snowball. We treated this sprint as a significant learning experience about proper scoping and understanding our limits. </p>

							<p class="content-body">In the Third Sprint, we kept our same goal as before to finish adding autonomy to Frost, but this time with renewed vigor. I joined Jeremy in experimenting and developing finding and tracking. I discovered a robust method through body detection that used machine learning to search for the contours of a human body, and together Jeremy and I worked on developing this method. We managed to bring accuracy of detecting a human body up to over 90%, and I optimized the algorithm to ensure constant, consistent output so that the actuators would always know where to go. I worked with Cedric on the LIDAR, mainly in creating a multiprocessing code architecture to integrate it with the data from the body detection module. I also wrote out the decision making algorithm that told Frost where to point and how far to shoot based on inputs from the Kinect and the LIDAR. By the end of the third sprint, we had successfully created an intelligent version of Frost, capable of finding targets on its own and firing towards them with a successful hit percentage of about 80%. </p>

							<p class="content-body">In the Fourth and Final Sprint, it was the home stretch, and our goal was to finish building the final robot and integrate all our intelligence on the final version. For the software team, this meant optimizing the LIDAR, body detection, and integration modules and making sure they were perfect. I took on the task of optimizing the software modules, and Jeremy decided to create a nice website to document our work. I managed to stabilize LIDAR output and optimize the body detection module to correctly detect and track bodies almost 100% of the time, with constant output. Finally, I improved the integration and decision making algorithms such that Frost's firing accuracy was about 98%, always shooting within 6 inches of the target's center, which is almost a guaranteed hit. After that, I worked with the team to build the catapult. We finished fabricating and assembling our final catapult, which was bigger, made of metal, and much stronger than the prototype. We also remade our circuit boards and other electrical components to accommodate for the new robot. With the finished Mechanical, Software, and Electrical components ready, we finished our project by integrating all the parts together and improving the final product until it was ready. We completed Frost in December 2016. </p>

							<p class="content-body"> Come Olin EXPO, we showcased Frost to the community and let guests have a test run with getting found and shot at by Frost up to 40 feet away. Unfortunately, there was no snow that day, so we settled with a plushy toy. Even then, the crowd was blown away by our work, and many people wanted multiple turns. After some documentation and publicity work, we have completed our work with Frost - the Autonomous Snowball Launcher. Come next semester, when the snow begins to fall, the people who once gaped in amazement will soon run in fear when we return from winter break to dominate the snowball game. </p>

							<div class="row">
								<div class="col-md-6">
									<img class="img-responsive" src="Images/FrostTracking.png" style="width:100%; height:300px">
								</div>
								<div class="col-md-6">
									<img class="img-responsive" src="Images/FrostMVP.png" style="width:100%; height:300px">
								</div>
							</div>



							<ul>
								<li>
									<a target="_blank" href="https://github.com/kzhang8850/Frost">
										<i class="fa fa-github fa-3x"></i>
									</a>
								</li>
								<li>
									<a target="_blank" href="http://poe.olin.edu/2016/STARK/">
										<i class="fa fa-globe fa-3x"></i>
									</a>
								</li>
							</ul>

							<button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Close Project </button>

						</div>
					</div>
				</div>

			</div>
		</div>
	</div>





	<div class="portfolio-modal modal fade" id="aquaponics" role="dialog" aria-hidden="true">
		<div class="modal-content">
			<div class='close-modal' data-dismiss="modal">
				<div class="lr">
					<div class="rl">
					</div>
				</div>
			</div>

			<div class="container">
				<div class="row">
					<div class='col-md-8 col-md-offset-2'>
						<div class="modal-body">
							<h2>Olin Aquaponics</h2>
							<p class="item-intro text-muted">OWL Extension Project Team</p>

							<p class="item-intro text-muted">Fall 2015 - Present</p>

							<div class="row">
								<p> Fall 2015</p>
							</div>
							<div class="row">
								<div class="col-md-4">

									<img class="img-responsive" src="Images/Aquaponics2015.jpg" style="width:100%; height:300px">
								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/AquaponicsProject.jpg" style="width:100%; height:300px">
								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/AquaponicsRelay.JPG" style="width:100%; height:300px">
								</div>
							</div>

							<p class="content-body">In the Fall of 2015, my first semester at Olin College, I joined a team of individuals that embarked on an extension of the original "Olin Workshop on the Library", a remodeling of the library to include a giant aquaponics aquarium. Aquaponics is like sustainable hydroponics, where marine and plants live in a symbiotic relationship of sustainable growth. The plan is to eventually incorporate this idea into the library. Our first step was to build a small operating aquaponics system to prove feasibility. I was mainly involved in the electrial portion of the project, designing and creating the relay system, monitor system, pumps, and lights. We presented the result of a semester's worth of work at the Olin Expo, where we demonstrated a functional system. Students and faculty alike were excited at our progress and looking forward to our efforts next semester.</p>

							<div class="row">
								<p> Spring 2016</p>
							</div>
							<div class="row">
								<div class="col-md-6">
									<img class="img-responsive" src="Images/AquaponicsDemo.JPG" style="width:100%; height:300px">
								</div>
								<div class="col-md-6">
									<img class="img-responsive" src="Images/Aquaponics2016.jpg" style="width:100%; height:300px">
								</div>
							</div>

							<p class="content-body">In the Spring of 2016, there was a transition of leadership, as the original seniors who started the club appointed a friend Nick and me as the new leaders of the club. After figuring things out, we officially began in the middle of the semester. Our work this semester consisted mainly of turning our "functional" system from last semester into a polished, professional aquaponics system. This mainly involved designing and building a cabinet around the metal frame, improving the water works and pipelines, and ensuring ecological success with the plants and the nurtients. I was working all three portions of the project, as well as coordinating with the team for meeting times, and talking to faculty and the library for support and sponsorship. In the end we managed to create a complete Aquaponics Cabinet with healthy, fast-growing basil. Our yield was approximately 1 quart of basil per month. We presented our system at EXPO again, and this time was met with even more of a crowd and praise. We were even approached by neighboring schools and Olin faculty about the possiblities of working together or sponsorships, such as the Charles River Center's Horticulture Program. As the new co-president of the team starting next semeser, I'm eager to see what we can do in the Fall.</p>

							<div class="row">
								<p> Fall 2016</p>
							</div>
							<div class="row">
								<div class="col-md-6">

									<img class="img-responsive" src="Images/Aquaponics2017.jpg" style="width:100%; height:300px">
								</div>
								<div class="col-md-6">

									<img class="img-responsive" src="Images/AquaponicsAquarium.jpg" style="width:100%; height:300px">
								</div>
							</div>

							<p class="content-body"> In the Fall of 2016, as the new club co-leader, I managed to negotiate a new system with our new sponsor, the librarian, that would be built into a bookshelf, so that we would have a fully integrated system that would exist literally inside the library. Our goal for this semester was to design and start building a functional version of our new system. The new system would be twice as big as the old system, and it would have a fully functional aquarium outfitted with aqua life, making it a complete aquaponics system. Once functional, it would have a yield of about 1 peck per month, and it would use even less energy and require less maintenance than the old system. As co-leader, I dealt with the high level organizational work, such as talking with sponsors and buying supplies from vendors, handling budget and logistics, and streamlining workflow among the subteams. We also attracted new members and raised team membership from less than 10 to over 20. On the techincal side, I worked with all subteams, including plumbing, ecological, electrical, and mechanical, making sure that teams were progressing smoothly, ensuring inter-team communication, and solving technical problems that arose in the teams. I designed the sensors for the system, such as water level and plant growth sensor systems. I was also in charge of maintaining the old system, as we were still growing basil in it. Due to technical diffculties, we were unable to finish the functional system, although we do have all the components flushed out and built. We presented our work at EXPO again, and this time was met with renewed interest at the possiblity and progress of a "sustainable garden" in the library. We made a lot of progress this semester, and I'm sure that by the end of next semester, we'll have completed the second system. </p>

							<div class="row">
								<p> Spring 2017</p>
							</div>
							<div class="row">
								<div class="col-md-8 col-md-offset-2">
									<img class="img-responsive" src="Images/Aquaponics_shelf.jpg" style="width:100%; height:300px">
								</div>

							</div>

							<div class="row">
								<div class="col-md-4">

									<img class="img-responsive" src="Images/Aquaponics_lights.jpg" style="width:100%; height:300px">
								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/Aquaponics_plumbing.jpg" style="width:100%; height:300px">
								</div>
								<div class="col-md-4">

									<img class="img-responsive" src="Images/Aquaponics_eco.jpg" style="width:100%; height:300px">
								</div>
							</div>

							<p class="content-body"> In the Spring of 2017, I doubled down on efforts to build the library shelf system. We hit the ground running and immediately began plans for construction. I worked extensively on maintaining the old system while also helping with the electrical team to create the sensors and control box. My team of organizers and I also put in the extra effort to coordinate between teams and ensure that the direction one team was going would complement the direction of another team. I made sure to talk to each subteam lead every meeting to keep up to date on their activities and inciting discussions between teams should unknown conflicts be discovered. Due to our efforts to improve coordination, we actually caught a number of pitfalls where teams were planning on constructing conflicting designs, thus preventing a potential disaster come build time. As the principal lead, I also dealt with the high level organizational work, such as buying supplies from vendors, handling budget and logistics, and maintaining a steady schedule for the subteams. Our design changed a number of times as we encouraged and performed numerous unit tests to ensure functionality. Iterative prototyping was used extensively throughout all teams, at the advice of the organizers. By the end of the semester and a few late nights on behalf of the organizers, we had successfully built out the library shelf. We even tested its functionality and managed to grow some starter basil in it. Our system could fit up to 75 individual basil plants, and the system's efficient nutrient distribution expedited growth times for potentially monthly harvests. The school librarian was very impressed with our finished system, and at EXPO, while we couldn't bring the system with us since it was set into the library wall, we heard ample compliments from visitors and some buzzing talk among the crowd about a plant farm and an aquarium in the Olin library. But of course, this is just the bare bones of a functional system. Come next semester, we plan on iterating further on this system and improving its aesthetic and mechanisms. Once the library shelf system is fully polished and operational, we will be able to advance our mission of creating a sustainable garden in the Olin library.</p>


							<ul>
								<li>
									<a target="_blank" href="https://drive.google.com/file/d/0B50p5hK2xeWgZmFrZnMtWjY5eVk/view?usp=sharing">
										<i class="fa fa-file-pdf-o fa-3x"></i>
									</a>
								</li>
								<li>
									<a target="_blank" href="https://drive.google.com/file/d/0B50p5hK2xeWgWmxud2RGc0o5cnM/view?usp=sharing">
										<i class="fa fa-file-pdf-o fa-3x">1</i>
									</a>
								</li>
								<li>
									<a target="_blank" href="https://drive.google.com/file/d/0B50p5hK2xeWgaER1R0pUX194X0k/view?usp=sharing">
										<i class="fa fa-file-pdf-o fa-3x">2</i>
									</a>
								</li>
								<li>
									<a target="_blank" href="https://drive.google.com/file/d/0B6-SxZvJ7FNNeDlnR0hXcTdKeDA/view?usp=sharing">
										<i class="fa fa-file-pdf-o fa-3x">3</i>
									</a>
								</li>
							</ul>

							<button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Close Project </button>





						</div>
					</div>
				</div>

			</div>
		</div>
	</div>






		<div id='socialsection'>
			<div class='container'>

				<div class='social'>
					<ul>
						<li>
							<a href="mailto:kevin.zhang@students.olin.edu">
								<i class="fa fa-envelope fa-3x"></i>
							</a>

						</li>
						<li>
							<a target="_blank" href="https://www.linkedin.com/in/kzhang8850">
								<i class="fa fa-linkedin  fa-3x"></i>
							</a>

						</li>
						<li>
							<a target="_blank" href="https://github.com/kzhang8850">
								<i class="fa fa-github fa-3x"></i>
							</a>

						</li>
					</ul>

				</div>

			</div>

		</div>


		<div id='footer'>
			<div class='container'>
				<div class="row">
					<div class="col-sm-4">
						<div class="copyright">
							<p>Copyright &#169 kevinwzhang.com 2017</p>
						</div>
					</div>
					<div class="col-sm-4">
					</div>
					<div class="col-sm-4">
						<div class="Madefrom">

							<p>Made with HTML5, JavaScript, CSS</p>
						</div>
					</div>

				</div>
			</div>
		</div>
	</div>

	<!-- jQuery -->
    <script src="js/jquery.js"></script>
    <script src="js/slideshow.js"></script>
		<script src="js/links.js"></script>
    <!--<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>-->

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Scrolling Nav JavaScript -->
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/scrolling-nav.js"></script>



</body>
</html>
